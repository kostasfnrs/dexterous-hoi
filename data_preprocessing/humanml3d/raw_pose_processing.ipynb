{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation\n",
    "import pytorch3d\n",
    "\n",
    "\n",
    "from human_body_prior.tools.omni_tools import copy2cpu as c2c\n",
    "\n",
    "os.environ['PYOPENGL_PLATFORM'] = 'egl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/media/erik/DATA'\n",
    "# raw_data_dir = f'{data_root}/behave_raw'\n",
    "# stage_1_output = f'{data_root}/behave_processed/pose_data_behave'\n",
    "# stage_2_output = f'{data_root}/behave_processed/joints_behave'\n",
    "\n",
    "raw_data_dir = f'{data_root}/grab/grab_preprocessed'\n",
    "stage_1_output = f'{data_root}/grab/pose_data_grab'\n",
    "stage_2_output = f'{data_root}/grab/joints_grab'\n",
    "\n",
    "# raw_data_dir = '/media/erik/DATA/grab_preprocessed'\n",
    "# stage_1_output = '/media/erik/DATA/pose_data_grab'\n",
    "# stage_2_output = '/media/erik/DATA/joints_grab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation device: cpu\n"
     ]
    }
   ],
   "source": [
    "# comp_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# this needs some really high memory GPUs, so default to CPU\n",
    "comp_device = torch.device(\"cpu\")\n",
    "\n",
    "print('Computation device:', comp_device)\n",
    "# %%\n",
    "from human_body_prior.body_model.body_model import BodyModel\n",
    "\n",
    "male_bm_path = './body_models/smplh/male/model.npz'\n",
    "male_dmpl_path = './body_models/dmpls/male/model.npz'\n",
    "\n",
    "female_bm_path = './body_models/smplh/female/model.npz'\n",
    "female_dmpl_path = './body_models/dmpls/female/model.npz'\n",
    "\n",
    "num_betas = 10 # number of body parameters\n",
    "num_dmpls = 8 # number of DMPL parameters\n",
    "\n",
    "# male_bm = BodyModel(bm_fname=male_bm_path, num_betas=num_betas, num_dmpls=num_dmpls, dmpl_fname=male_dmpl_path).to(comp_device)\n",
    "male_bm = BodyModel(bm_fname=male_bm_path, num_betas=num_betas).to(comp_device)\n",
    "faces = c2c(male_bm.f)\n",
    "\n",
    "# female_bm = BodyModel(bm_fname=female_bm_path, num_betas=num_betas, num_dmpls=num_dmpls, dmpl_fname=female_dmpl_path).to(comp_device)\n",
    "female_bm = BodyModel(bm_fname=female_bm_path, num_betas=num_betas).to(comp_device)\n",
    "\n",
    "paths = []\n",
    "folders = []\n",
    "dataset_names = []\n",
    "for root, dirs, files in os.walk(raw_data_dir):\n",
    "    folders.append(root)\n",
    "    for name in files:\n",
    "        dataset_name = root.split('/')[1]\n",
    "        if dataset_name not in dataset_names:\n",
    "            dataset_names.append(dataset_name)\n",
    "        if 'smpl_fit_all.npz' in files:\n",
    "            paths.append(os.path.join(root, 'smpl_fit_all.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch3d.transforms\n",
    "\n",
    "\n",
    "save_folders = [folder.replace(raw_data_dir, stage_1_output) for folder in folders]\n",
    "for folder in save_folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "group_path = [[path for path in paths if name in path] for name in dataset_names]\n",
    "\n",
    "# %%\n",
    "# trans_matrix = np.array([[1.0, 0.0, 0.0],\n",
    "#                             [0.0, -1.0, 0.0],\n",
    "#                             [0.0, 0.0, -1.0]])\n",
    "\n",
    "trans_matrix = np.array([[1.0, 0.0, 0.0],\n",
    "                            [0.0, 1.0, 0.0],\n",
    "                            [0.0, 0.0, 1.0]])\n",
    "\n",
    "ex_fps = 30\n",
    "def amass_to_pose(src_path, save_path):\n",
    "    seq_info_path = src_path.replace(\"smpl_fit_all.npz\", \"info.json\")\n",
    "    with open(seq_info_path, \"r\") as f:\n",
    "        seq_info = json.load(f)\n",
    "    gender = seq_info[\"gender\"]\n",
    "\n",
    "    src_path_obj = src_path.replace('smpl_fit_all.npz', 'object_fit_all.npz')\n",
    "\n",
    "    bdata = np.load(src_path, allow_pickle=True)\n",
    "    bdata_obj = np.load(src_path_obj, allow_pickle=True)\n",
    "\n",
    "    # load hand data\n",
    "    src_path_lhand = src_path.replace('smpl_fit_all.npz', 'lhand_data.npz')\n",
    "    src_path_rhand = src_path.replace('smpl_fit_all.npz', 'rhand_data.npz')\n",
    "    data_lhand = np.load(src_path_lhand, allow_pickle=True)\n",
    "    data_rhand = np.load(src_path_rhand, allow_pickle=True)\n",
    "    # bdata_lhand = bdata_lhand['joints'] # 1 x T x 21 x 3\n",
    "    # bdata_rhand = bdata_rhand['joints'] # 1 x T x 21 x 3\n",
    "\n",
    "    # bdata_lhand = torch.Tensor(bdata_lhand).to(comp_device).squeeze(0) # T x 21 x 3\n",
    "    # bdata_rhand = torch.Tensor(bdata_rhand).to(comp_device).squeeze(0) # T x 21 x 3\n",
    "\n",
    "    bdata_lhand = data_lhand['pca_pose'] # T x 24\n",
    "    bdata_rhand = data_rhand['pca_pose'] # T x 24\n",
    "\n",
    "    rot_euler_lhand = np.array(data_lhand['global_orient'])\n",
    "    rot_euler_rhand = np.array(data_rhand['global_orient'])\n",
    "\n",
    "    # TODO: fix this, the rotation is AXIS ANGLE, not euler angles, need to convert this approapriately on both ends of pipeline\n",
    "\n",
    "    # convert to 6d representation\n",
    "    # rot_lhand = Rotation.from_euler('xyz', rot_euler_lhand).as_matrix()\n",
    "    # rot_rhand = Rotation.from_euler('xyz', rot_euler_rhand).as_matrix()\n",
    "\n",
    "    rot_lhand = pytorch3d.transforms.axis_angle_to_matrix(torch.Tensor(rot_euler_lhand).to(comp_device))\n",
    "    rot_rhand = pytorch3d.transforms.axis_angle_to_matrix(torch.Tensor(rot_euler_rhand).to(comp_device))\n",
    "\n",
    "    # convert to continuous 6d representation\n",
    "    rot_lhand = pytorch3d.transforms.matrix_to_rotation_6d(rot_lhand).squeeze(0)\n",
    "    rot_rhand = pytorch3d.transforms.matrix_to_rotation_6d(rot_rhand).squeeze(0)\n",
    "\n",
    "    bdata_lhand = np.concatenate([bdata_lhand, rot_lhand], axis=-1) # T x 30\n",
    "    bdata_rhand = np.concatenate([bdata_rhand, rot_lhand], axis=-1) # T x 30\n",
    "    \n",
    "    assert bdata_lhand.shape[1] == 30 and bdata_rhand.shape[1] == 30\n",
    "\n",
    "\n",
    "    fps = 120\n",
    "    frame_number = bdata['trans'].shape[0]\n",
    "\n",
    "    fId = 0 # frame id of the mocap sequence\n",
    "    pose_seq = []\n",
    "    if gender == 'male':\n",
    "        bm = male_bm\n",
    "    else:\n",
    "        bm = female_bm\n",
    "    down_sample = int(fps / ex_fps)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        root_orient = torch.Tensor(bdata['poses'][::down_sample, :3]).to(comp_device) # controls the global root orientation \n",
    "\n",
    "        pose_body = torch.Tensor(bdata['poses'][::down_sample, 3:66]).to(comp_device) # controls the body\n",
    "        pose_hand = torch.Tensor(bdata['poses'][::down_sample, 66:]).to(comp_device) # controls the finger articulation\n",
    "        betas = torch.Tensor(bdata['betas'][::down_sample]).to(comp_device) # controls the body shape\n",
    "        trans = torch.Tensor(bdata['trans'][::down_sample]).to(comp_device)    \n",
    "        body = bm(pose_body=pose_body, pose_hand=pose_hand, betas=betas, root_orient=root_orient)\n",
    "        joint_loc = body.Jtr + trans[:, None]\n",
    "        pose_seq = joint_loc\n",
    "\n",
    "    # pose_seq = torch.cat(pose_seq, dim=0)\n",
    "    \n",
    "    pose_seq_np = pose_seq.detach().cpu().numpy()\n",
    "    pose_seq_np_n = np.dot(pose_seq_np, trans_matrix)\n",
    "    np.save(save_path, pose_seq_np_n)\n",
    "\n",
    "    # process obj pose data\n",
    "    angle, trans = bdata_obj['angles'], bdata_obj['trans']\n",
    "    rot = Rotation.from_rotvec(angle).as_matrix()\n",
    "    mat = np.eye(4)[np.newaxis].repeat(rot.shape[0], axis=0)\n",
    "    mat[:, :3, :3] = rot\n",
    "    mat[:, :3, 3] = trans\n",
    "    trans_matrix_eye4 = np.eye(4)[np.newaxis]\n",
    "    trans_matrix_eye4[0, :3, :3] = trans_matrix\n",
    "    mat = trans_matrix_eye4 @ mat\n",
    "\n",
    "    rot, trans = mat[:, :3, :3], mat[:, :3, 3]\n",
    "    rot = Rotation.from_matrix(rot).as_rotvec()\n",
    "    obj_pose = np.concatenate([rot, trans], axis=-1)\n",
    "\n",
    "    # downsample obj pose\n",
    "    obj_pose = obj_pose[::down_sample]\n",
    "    bdata_lhand = bdata_lhand[::down_sample]\n",
    "    bdata_rhand = bdata_rhand[::down_sample]\n",
    "\n",
    "    save_path_obj = save_path.replace('smpl_fit_all.npy', 'object_fit_all.npy')\n",
    "    np.save(save_path_obj, obj_pose)\n",
    "\n",
    "    save_path_lhand = save_path.replace('smpl_fit_all.npy', 'lhand_data.npy')\n",
    "    np.save(save_path_lhand, bdata_lhand)\n",
    "\n",
    "    save_path_rhand = save_path.replace('smpl_fit_all.npy', 'rhand_data.npy')\n",
    "    np.save(save_path_rhand, bdata_rhand)\n",
    "    \n",
    "    return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: erik:   0%|          | 0/9345 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "axis_angle_to_matrix() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mreplace(raw_data_dir, stage_1_output)\n\u001b[1;32m     13\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m save_path[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnpy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m     fps \u001b[38;5;241m=\u001b[39m \u001b[43mamass_to_pose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m cur_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(paths)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessed / All (fps \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m (fps, cur_count, all_count) )\n",
      "Cell \u001b[0;32mIn[10], line 53\u001b[0m, in \u001b[0;36mamass_to_pose\u001b[0;34m(src_path, save_path)\u001b[0m\n\u001b[1;32m     45\u001b[0m rot_euler_rhand \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data_rhand[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal_orient\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# TODO: fix this, the rotation is AXIS ANGLE, not euler angles, need to convert this approapriately on both ends of pipeline\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# convert to 6d representation\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# rot_lhand = Rotation.from_euler('xyz', rot_euler_lhand).as_matrix()\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# rot_rhand = Rotation.from_euler('xyz', rot_euler_rhand).as_matrix()\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m rot_lhand \u001b[38;5;241m=\u001b[39m \u001b[43mpytorch3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis_angle_to_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrot_euler_lhand\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp_device\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mXYZ\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m rot_rhand \u001b[38;5;241m=\u001b[39m pytorch3d\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39maxis_angle_to_matrix(torch\u001b[38;5;241m.\u001b[39mTensor(rot_euler_rhand)\u001b[38;5;241m.\u001b[39mto(comp_device), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXYZ\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# convert to continuous 6d representation\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: axis_angle_to_matrix() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "group_path = group_path\n",
    "all_count = sum([len(paths) for paths in group_path])\n",
    "cur_count = 0\n",
    "\n",
    "import time\n",
    "for paths in group_path:\n",
    "    dataset_name = paths[0].split('/')[2]\n",
    "    pbar = tqdm(paths)\n",
    "    pbar.set_description('Processing: %s'%dataset_name)\n",
    "    fps = 0\n",
    "    for path in pbar:\n",
    "        save_path = path.replace(raw_data_dir, stage_1_output)\n",
    "        save_path = save_path[:-3] + 'npy'\n",
    "        fps = amass_to_pose(path, save_path)\n",
    "        \n",
    "    cur_count += len(paths)\n",
    "    print('Processed / All (fps %d): %d/%d'% (fps, cur_count, all_count) )\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m         data[:, left_hand_chain] \u001b[38;5;241m=\u001b[39m tmp\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m---> 24\u001b[0m total_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mgroup_path\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     25\u001b[0m fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(total_amount)):\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import codecs as cs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import join as pjoin\n",
    "\n",
    "def swap_left_right(data):\n",
    "    assert len(data.shape) == 3 and data.shape[-1] == 3\n",
    "    data = data.copy()\n",
    "    data[..., 0] *= -1\n",
    "    right_chain = [2, 5, 8, 11, 14, 17, 19, 21]\n",
    "    left_chain = [1, 4, 7, 10, 13, 16, 18, 20]\n",
    "    left_hand_chain = [22, 23, 24, 34, 35, 36, 25, 26, 27, 31, 32, 33, 28, 29, 30]\n",
    "    right_hand_chain = [43, 44, 45, 46, 47, 48, 40, 41, 42, 37, 38, 39, 49, 50, 51]\n",
    "    tmp = data[:, right_chain]\n",
    "    data[:, right_chain] = data[:, left_chain]\n",
    "    data[:, left_chain] = tmp\n",
    "    if data.shape[1] > 24:\n",
    "        tmp = data[:, right_hand_chain]\n",
    "        data[:, right_hand_chain] = data[:, left_hand_chain]\n",
    "        data[:, left_hand_chain] = tmp\n",
    "    return data\n",
    "\n",
    "total_amount = len(group_path[0])\n",
    "fps = 30\n",
    "\n",
    "for i in tqdm(range(total_amount)):\n",
    "    path = group_path[0][i]\n",
    "    source_path = path.replace(raw_data_dir, stage_1_output)\n",
    "    source_path = source_path[:-3] + 'npy'\n",
    "    try:\n",
    "        data = np.load(source_path)\n",
    "    except:\n",
    "        print('Error: ', source_path)\n",
    "        continue\n",
    "    new_name = source_path.split('/')[-2]\n",
    "    # data[..., 0] *= -1\n",
    "    \n",
    "    # data_m = swap_left_right(data)\n",
    "\n",
    "    source_path_obj = source_path.replace('smpl_fit_all.npy', 'object_fit_all.npy')\n",
    "    data_obj = np.load(source_path_obj)\n",
    "    if not os.path.exists(stage_2_output):\n",
    "        os.makedirs(stage_2_output, exist_ok=True)\n",
    "\n",
    "    np.save(pjoin(stage_2_output, new_name), data)\n",
    "    # np.save(pjoin(save_dir, 'M'+new_name), data_m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
